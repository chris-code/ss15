{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding numerical pitfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The harmonic series is convergent in floating point arithmetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\sum_{n=1}^{\\infty} \\; \\frac{1}{n} \\quad = \\quad 34.1220356680478715816207113675773143768310546875\n",
    "\\end{align*}\n",
    "\n",
    "(usually it is famously known to diverge to $\\infty$)\n",
    "\n",
    "### References\n",
    "\n",
    "Proof of divergence:\n",
    "http://www.free-education-resources.com/www.mathematik.net/harmonische-reihen/hr1s20.htm\n",
    "\n",
    "Proof of convergence for floating point:\n",
    "http://www.maths.tcd.ie/pub/ims/bull71/recipnote.pdf\n",
    "\n",
    "Resolution:\n",
    "http://fredrik-j.blogspot.de/2009/02/how-not-to-compute-harmonic-numbers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "http://www.johndcook.com/blog/2009/04/06/numbers-are-a-leaky-abstraction/\n",
    "\n",
    "http://www.codeproject.com/Articles/29637/Five-Tips-for-Floating-Point-Programming\n",
    "\n",
    "http://www.codeproject.com/Articles/25294/Avoiding-Overflow-Underflow-and-Loss-of-Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In floating point arithmetic, subtraction is rather inaccurate. Observe that 2-1.8 is not 0.2.\n",
    "However, Python catches this well known phenomenon in its str-method and converts the output to a convenient number. The following two lines illustrate not only numeric subtaction inaccuracy, but also the difference between `repr` and `str`. `repr` is designed to represent the value accurately, while `str` is intended for a convenient output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999996\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print repr(2-1.8)\n",
    "print str(2-1.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to mention for completeness: Don't use exact equals-operator on floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print (2-1.8 == 0.2)\n",
    "#Python-hack that actually works surprisingly well:\n",
    "print (str(2-1.8) == str(0.2))\n",
    "\n",
    "#Recommended method with control over matching-precision:\n",
    "threshold = 0.000000001\n",
    "print ((2-1.8) - 0.2 < threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve a quadratic equation. Naive solving becomes bad if low and large coefficients occur.\n",
    "Consider the equation $3 x^2 + 10^6 x + 5 = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pq\n",
      "(0.0, -33333333.333333332)\n",
      "0.005\n",
      "0.005\n",
      "pq2\n",
      "(-5.000000000000001e-11, -33333333.333333332)\n",
      "-8.673617379884035e-19\n",
      "0.005\n",
      "companion\n",
      "array([ -3.72529030e-09,  -3.33333333e+07])\n",
      "-0.36752902984619135\n",
      "0.0050000000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = 3.0\n",
    "b = 10e7\n",
    "c = 0.005\n",
    "\n",
    "def f(x):\n",
    "    return a*x**2+b*x+c\n",
    "\n",
    "def solve_pq():\n",
    "    p = b/a\n",
    "    q = c/a\n",
    "    D = (p/2.0)**2 - q\n",
    "    r1 = -p/2.0+D**0.5\n",
    "    r2 = -p/2.0-D**0.5\n",
    "    return (r1, r2)\n",
    "\n",
    "def solve_pq2():\n",
    "    p = b/a\n",
    "    q = c/a\n",
    "    D = (p/2.0)**2 - q\n",
    "    r1 = -2.0*q/(p+2.0*D**0.5)\n",
    "    r2 = -p/2.0-D**0.5\n",
    "    return (r1, r2)\n",
    "\n",
    "def solve_companion():\n",
    "    p = b/a\n",
    "    q = c/a\n",
    "    C = np.array([[0.0, -q], [1.0, -p]])\n",
    "    return np.linalg.eigvals(C)\n",
    "\n",
    "result = solve_pq()\n",
    "print \"pq\"\n",
    "print repr(result)\n",
    "print repr(f(result[0]))\n",
    "print repr(f(result[1]))\n",
    "\n",
    "result = solve_pq2()\n",
    "print \"pq2\"\n",
    "print repr(result)\n",
    "print repr(f(result[0]))\n",
    "print repr(f(result[1]))\n",
    "\n",
    "result = solve_companion()\n",
    "print \"companion\"\n",
    "print repr(result)\n",
    "print repr(f(result[0]))\n",
    "print repr(f(result[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't invert that matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "http://www.johndcook.com/blog/2010/01/19/dont-invert-that-matrix/\n",
    "\n",
    "### Summary:\n",
    "\n",
    "* There's hardly ever a good reason to invert a matrix\n",
    "* Solve linear equation systems directly\n",
    "* Apply a QR-decomposition to solve multiple systems with the same matrix (but different right side)\n",
    "* Even if the inverse is given for free, direct solving is still more accurate\n",
    "* Inverses of sparse matrices are in general dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Horner's method for numerically stable evaluation\n",
    "* NumPy's Polynome-class has this built-in\n",
    "\n",
    "### For expansion:\n",
    "\n",
    "* sometimes we use monomials to expand input data\n",
    "* a subsequent algorithm is supposed to figure out the factors and assemble polynomials\n",
    "* these will be unstable in a naive approach\n",
    "* instead of monomials use a numerically stable base like legendre polynomials\n",
    "* you might need to adjust them for your value-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
